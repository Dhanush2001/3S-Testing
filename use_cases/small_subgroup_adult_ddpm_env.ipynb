{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd5ee888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KeOps] Warning : CUDA libraries not found or could not be loaded; Switching to CPU only.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-12-05T22:57:39.359882-0500][58275][CRITICAL] module disabled: /home/dhanush/anaconda3/envs/3s/lib/python3.9/site-packages/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2025-12-05T22:57:39.360869-0500][58275][CRITICAL] load failed: \n",
      "arfpy is not installed. Please install it with pip install arfpy.\n",
      "Please be aware that arfpy is only available for python >= 3.8.\n",
      "\n",
      "[2025-12-05T22:57:39.361217-0500][58275][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_arf' has no attribute 'plugin'\n",
      "[2025-12-05T22:57:39.361690-0500][58275][CRITICAL] module plugin_arf load failed\n",
      "[2025-12-05T22:57:39.360869-0500][58275][CRITICAL] load failed: \n",
      "arfpy is not installed. Please install it with pip install arfpy.\n",
      "Please be aware that arfpy is only available for python >= 3.8.\n",
      "\n",
      "[2025-12-05T22:57:39.361217-0500][58275][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_arf' has no attribute 'plugin'\n",
      "[2025-12-05T22:57:39.361690-0500][58275][CRITICAL] module plugin_arf load failed\n",
      "[2025-12-05T22:57:39.372403-0500][58275][CRITICAL] load failed: \n",
      "GReaT is not installed. Please install it with pip install GReaT.\n",
      "Please be aware that GReaT is only available for python >= 3.9.\n",
      "\n",
      "[2025-12-05T22:57:39.372930-0500][58275][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-12-05T22:57:39.373284-0500][58275][CRITICAL] module plugin_great load failed\n",
      "[2025-12-05T22:57:39.372403-0500][58275][CRITICAL] load failed: \n",
      "GReaT is not installed. Please install it with pip install GReaT.\n",
      "Please be aware that GReaT is only available for python >= 3.9.\n",
      "\n",
      "[2025-12-05T22:57:39.372930-0500][58275][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-12-05T22:57:39.373284-0500][58275][CRITICAL] module plugin_great load failed\n",
      "[2025-12-05T22:57:39.458044-0500][58275][CRITICAL] load failed: unsupported operand type(s) for |: 'type' and 'type'\n",
      "[2025-12-05T22:57:39.458573-0500][58275][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_bayesian_network' has no attribute 'plugin'\n",
      "[2025-12-05T22:57:39.458990-0500][58275][CRITICAL] module plugin_bayesian_network load failed\n",
      "[2025-12-05T22:57:39.466831-0500][58275][CRITICAL] load failed: unsupported operand type(s) for |: 'type' and 'type'\n",
      "[2025-12-05T22:57:39.467356-0500][58275][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_privbayes' has no attribute 'plugin'\n",
      "[2025-12-05T22:57:39.467823-0500][58275][CRITICAL] module plugin_privbayes load failed\n",
      "[2025-12-05T22:57:39.458044-0500][58275][CRITICAL] load failed: unsupported operand type(s) for |: 'type' and 'type'\n",
      "[2025-12-05T22:57:39.458573-0500][58275][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_bayesian_network' has no attribute 'plugin'\n",
      "[2025-12-05T22:57:39.458990-0500][58275][CRITICAL] module plugin_bayesian_network load failed\n",
      "[2025-12-05T22:57:39.466831-0500][58275][CRITICAL] load failed: unsupported operand type(s) for |: 'type' and 'type'\n",
      "[2025-12-05T22:57:39.467356-0500][58275][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_privbayes' has no attribute 'plugin'\n",
      "[2025-12-05T22:57:39.467823-0500][58275][CRITICAL] module plugin_privbayes load failed\n",
      "[2025-12-05T22:57:39.470098-0500][58275][CRITICAL] load failed: unsupported operand type(s) for |: 'type' and 'type'\n",
      "[2025-12-05T22:57:39.470727-0500][58275][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2025-12-05T22:57:39.471237-0500][58275][CRITICAL] module plugin_decaf load failed\n",
      "[2025-12-05T22:57:39.470098-0500][58275][CRITICAL] load failed: unsupported operand type(s) for |: 'type' and 'type'\n",
      "[2025-12-05T22:57:39.470727-0500][58275][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2025-12-05T22:57:39.471237-0500][58275][CRITICAL] module plugin_decaf load failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synthcity from /home/dhanush/anaconda3/envs/3s/lib/python3.9/site-packages/synthcity/__init__.py\n",
      "DDPM available: True\n",
      "DDPM available: True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import site\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "repo_root = Path('/home/dhanush/work/3S-Testing').resolve()\n",
    "repo_synthcity = repo_root / 'synthcity'\n",
    "sys.path = [p for p in sys.path if str(repo_synthcity) not in str(p)]\n",
    "for sp in reversed(site.getsitepackages() if hasattr(site, 'getsitepackages') else []):\n",
    "    if sp in sys.path:\n",
    "        sys.path.remove(sp)\n",
    "    sys.path.insert(0, sp)\n",
    "if str(repo_root) not in sys.path:\n",
    "    sys.path.append(str(repo_root))\n",
    "\n",
    "from synthcity.plugins import Plugins\n",
    "import synthcity\n",
    "from src.data_loader import load_adult_data\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "print('synthcity from', synthcity.__file__)\n",
    "print('DDPM available:', 'ddpm' in Plugins().list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f021fb9e",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85fd627e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shapes: (45222, 12) (11394, 12) (3166, 12)\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'adult'\n",
    "X_train, X_oracle, y_train, y_test, X, y = load_adult_data()\n",
    "Data = X.copy()\n",
    "Data['y'] = y\n",
    "# matching original notebook split ratios\n",
    "X_train, X_oracle = train_test_split(Data, test_size=0.65, random_state=seed)\n",
    "X_train, X_test = train_test_split(X_train, test_size=0.2, random_state=seed)\n",
    "X_train, X_hp = train_test_split(X_train, test_size=0.1, random_state=seed)\n",
    "print('Data shapes:', Data.shape, X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b23f988",
   "metadata": {},
   "source": [
    "# Train Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a1441e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-12-05T22:57:40.131737-0500][58275][CRITICAL] module disabled: /home/dhanush/anaconda3/envs/3s/lib/python3.9/site-packages/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2025-12-05T22:57:40.132363-0500][58275][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_arf' has no attribute 'plugin'\n",
      "[2025-12-05T22:57:40.132756-0500][58275][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_arf' has no attribute 'plugin'\n",
      "[2025-12-05T22:57:40.133058-0500][58275][CRITICAL] module plugin_arf load failed\n",
      "[2025-12-05T22:57:40.133457-0500][58275][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-12-05T22:57:40.133764-0500][58275][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-12-05T22:57:40.134057-0500][58275][CRITICAL] module plugin_great load failed\n",
      "[2025-12-05T22:57:40.134472-0500][58275][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_bayesian_network' has no attribute 'plugin'\n",
      "[2025-12-05T22:57:40.134808-0500][58275][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_bayesian_network' has no attribute 'plugin'\n",
      "[2025-12-05T22:57:40.135128-0500][58275][CRITICAL] module plugin_bayesian_network load failed\n",
      "[2025-12-05T22:57:40.135887-0500][58275][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_privbayes' has no attribute 'plugin'\n",
      "[2025-12-05T22:57:40.136309-0500][58275][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_privbayes' has no attribute 'plugin'\n",
      "[2025-12-05T22:57:40.136608-0500][58275][CRITICAL] module plugin_privbayes load failed\n",
      "[2025-12-05T22:57:40.136984-0500][58275][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2025-12-05T22:57:40.137430-0500][58275][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2025-12-05T22:57:40.137825-0500][58275][CRITICAL] module plugin_decaf load failed\n",
      "[2025-12-05T22:57:40.132363-0500][58275][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_arf' has no attribute 'plugin'\n",
      "[2025-12-05T22:57:40.132756-0500][58275][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_arf' has no attribute 'plugin'\n",
      "[2025-12-05T22:57:40.133058-0500][58275][CRITICAL] module plugin_arf load failed\n",
      "[2025-12-05T22:57:40.133457-0500][58275][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-12-05T22:57:40.133764-0500][58275][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-12-05T22:57:40.134057-0500][58275][CRITICAL] module plugin_great load failed\n",
      "[2025-12-05T22:57:40.134472-0500][58275][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_bayesian_network' has no attribute 'plugin'\n",
      "[2025-12-05T22:57:40.134808-0500][58275][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_bayesian_network' has no attribute 'plugin'\n",
      "[2025-12-05T22:57:40.135128-0500][58275][CRITICAL] module plugin_bayesian_network load failed\n",
      "[2025-12-05T22:57:40.135887-0500][58275][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_privbayes' has no attribute 'plugin'\n",
      "[2025-12-05T22:57:40.136309-0500][58275][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_privbayes' has no attribute 'plugin'\n",
      "[2025-12-05T22:57:40.136608-0500][58275][CRITICAL] module plugin_privbayes load failed\n",
      "[2025-12-05T22:57:40.136984-0500][58275][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2025-12-05T22:57:40.137430-0500][58275][CRITICAL] load failed: module 'synthcity.plugins.privacy.plugin_decaf' has no attribute 'plugin'\n",
      "[2025-12-05T22:57:40.137825-0500][58275][CRITICAL] module plugin_decaf load failed\n",
      "Epoch: 100%|██████████| 1000/1000 [03:27<00:00,  4.82it/s, loss=0.88]\n",
      "Epoch: 100%|██████████| 1000/1000 [03:27<00:00,  4.82it/s, loss=0.88]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained DDPM 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 1000/1000 [03:42<00:00,  4.50it/s, loss=0.883]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained DDPM 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 1000/1000 [03:25<00:00,  4.86it/s, loss=0.883]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained DDPM 3/3\n",
      "Sampler ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "discrete_columns = [\n",
    "    'education-num','marital-status','employment_type','relationship','race','sex','country','y'\n",
    "]\n",
    "use_trained_model = False\n",
    "n_generators = 3\n",
    "ddpms = []\n",
    "\n",
    "class DDPMSampler:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    def sample(self, n, condition_column=None, condition_value=None):\n",
    "        gen_count = max(n, int(n*2)) if condition_column is not None else n\n",
    "        try:\n",
    "            out = self.model.generate(count=gen_count)\n",
    "        except Exception:\n",
    "            try:\n",
    "                out = self.model.sample(count=gen_count)\n",
    "            except Exception as e:\n",
    "                raise RuntimeError('Generation failed: ' + str(e))\n",
    "        try:\n",
    "            df = out.dataframe()\n",
    "        except Exception:\n",
    "            df = pd.DataFrame(out)\n",
    "        if condition_column is not None and condition_value is not None:\n",
    "            df = df[df[condition_column] == condition_value]\n",
    "        return df.head(n)\n",
    "\n",
    "if not use_trained_model:\n",
    "    base = Plugins().get('ddpm')\n",
    "    for i in range(n_generators):\n",
    "        model = base() if callable(base) else type(base)()\n",
    "        try:\n",
    "            model.fit(X_train, discrete_columns=discrete_columns, n_iterations=50, seed=seed+i)\n",
    "        except TypeError:\n",
    "            try:\n",
    "                model.fit(X_train, discrete_columns=discrete_columns, iterations=50, seed=seed+i)\n",
    "            except TypeError:\n",
    "                model.fit(X_train, discrete_columns=discrete_columns, seed=seed+i)\n",
    "        ddpms.append(model)\n",
    "        print(f'Trained DDPM {i+1}/{n_generators}')\n",
    "    ddpm_samplers = [DDPMSampler(m) for m in ddpms]\n",
    "    ddpm_sampler = ddpm_samplers[0]\n",
    "else:\n",
    "    loaded = Plugins().get('ddpm')\n",
    "    ddpm_sampler = DDPMSampler(loaded.load(f'../models/ddpm_{dataset_name}'))\n",
    "print('Sampler ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9510658",
   "metadata": {},
   "source": [
    "# Train the downstream predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b46ce11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained downstream predictors\n"
     ]
    }
   ],
   "source": [
    "model_dict = {\n",
    "    'mlp': MLPClassifier(random_state=seed),\n",
    "    'knn': KNeighborsClassifier(),\n",
    "    'dt': DecisionTreeClassifier(random_state=seed),\n",
    "    'rf': RandomForestClassifier(random_state=seed),\n",
    "    'gbc': GradientBoostingClassifier(random_state=seed),\n",
    "    'bag': BaggingClassifier(random_state=seed),\n",
    "    'ada': AdaBoostClassifier(random_state=seed),\n",
    "    'svm': SVC(random_state=seed),\n",
    "    'lr': LogisticRegression(random_state=seed),\n",
    "}\n",
    "\n",
    "def train_models(df, model_dict):\n",
    "    trained = {}\n",
    "    for name, clf in model_dict.items():\n",
    "        trained[name] = clf.fit(df.drop('y', axis=1), df['y'])\n",
    "    return trained\n",
    "\n",
    "trained_model_dict = train_models(X_train, model_dict)\n",
    "print('Trained downstream predictors')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee77e18",
   "metadata": {},
   "source": [
    "# Run analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c06aba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [28:23<00:00, 567.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 3 runs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "column_metric = 'race'\n",
    "groups = list(np.unique(Data[column_metric]))\n",
    "\n",
    "\n",
    "def evaluate_models(data):\n",
    "    results = {}\n",
    "    for g in groups:\n",
    "        results[g] = {'acc': {}}\n",
    "        subset = data[data[column_metric] == g]\n",
    "        if len(subset) == 0:\n",
    "            for m in trained_model_dict.keys():\n",
    "                results[g]['acc'][m] = 0.0\n",
    "            continue\n",
    "        for m, clf in trained_model_dict.items():\n",
    "            try:\n",
    "                y_pred = clf.predict(subset.drop('y', axis=1))\n",
    "                results[g]['acc'][m] = accuracy_score(subset['y'], y_pred)\n",
    "            except Exception:\n",
    "                results[g]['acc'][m] = 0.0\n",
    "    return results\n",
    "\n",
    "\n",
    "def run_analysis(random_state=0):\n",
    "    X_tr, X_or = train_test_split(Data, test_size=0.65, random_state=0)\n",
    "    X_tr, X_te = train_test_split(X_tr, test_size=0.2, random_state=random_state)\n",
    "\n",
    "    oracle_results = evaluate_models(X_or)\n",
    "    oracle_samples = {g: X_or[X_or[column_metric]==g].shape[0] for g in groups}\n",
    "\n",
    "    test_results = evaluate_models(X_te)\n",
    "    test_samples = {g: X_te[X_te[column_metric]==g].shape[0] for g in groups}\n",
    "\n",
    "    synth_df_list = []\n",
    "    for g in groups:\n",
    "        synth_df = ddpm_sampler.sample(len(X_tr), condition_column=column_metric, condition_value=g)\n",
    "        synth_df_list.append(synth_df)\n",
    "    synth_data = pd.concat(synth_df_list, ignore_index=True) if len(synth_df_list)>0 else pd.DataFrame()\n",
    "\n",
    "    if len(synth_data) > 0:\n",
    "        synth_results = evaluate_models(synth_data)\n",
    "        synth_samples = {g: synth_data[synth_data[column_metric]==g].shape[0] for g in groups}\n",
    "    else:\n",
    "        synth_results = {g:{'acc':{m:0.0 for m in trained_model_dict.keys()}} for g in groups}\n",
    "        synth_samples = {g:0 for g in groups}\n",
    "\n",
    "    aug_data = pd.concat([X_te, synth_data], ignore_index=True) if len(synth_data)>0 else X_te\n",
    "    aug_results = evaluate_models(aug_data)\n",
    "    aug_samples = {g: aug_data[aug_data[column_metric]==g].shape[0] for g in groups}\n",
    "\n",
    "    return test_results, test_samples, oracle_results, oracle_samples, synth_results, synth_samples, aug_results, aug_samples\n",
    "\n",
    "n_runs = 3\n",
    "test_acc_list=[]; oracle_acc_list=[]; synth_acc_list=[]; aug_acc_list=[]\n",
    "test_samples_list=[]; oracle_samples_list=[]; synth_samples_list=[]; aug_samples_list=[]\n",
    "for i in tqdm(range(n_runs)):\n",
    "    res = run_analysis(random_state=i*100)\n",
    "    (tres, tsamp, ores, osamp, sres, ssamp, ares, asamp) = res\n",
    "    test_acc_list.append(tres); oracle_acc_list.append(ores); synth_acc_list.append(sres); aug_acc_list.append(ares)\n",
    "    test_samples_list.append(tsamp); oracle_samples_list.append(osamp); synth_samples_list.append(ssamp); aug_samples_list.append(asamp)\n",
    "print('Completed', n_runs, 'runs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6302d764",
   "metadata": {},
   "source": [
    "# Process results and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b0046a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ../results/adult_subgroup_shift_ddpm_env_rf_acc.csv\n",
      "     Group  Oracle  Synthetic  Augmented   Test\n",
      "0  1 (86%)   80.32      78.36      79.93  87.25\n",
      "1   2 (9%)   88.72      88.82      89.44  95.36\n",
      "2   3 (3%)   80.21      81.64      82.37  89.44\n",
      "3   4 (1%)   87.63      88.75      89.08  93.10\n",
      "4   5 (1%)   88.74      92.54      92.68  94.20\n"
     ]
    }
   ],
   "source": [
    "metrics = ['acc']\n",
    "models = ['rf']\n",
    "\n",
    "for metric in metrics:\n",
    "    for model in models:\n",
    "        props = [count/np.sum(np.unique(Data[column_metric], return_counts=True)[1]) for count in np.unique(Data[column_metric], return_counts=True)[1]]\n",
    "        df = pd.DataFrame(columns=['Group','Oracle','Synthetic','Augmented','Test'])\n",
    "        df_std = pd.DataFrame(columns=['Group','Oracle','Synthetic','Augmented','Test'])\n",
    "        for idx, g in enumerate(np.argsort(props)[::-1]):\n",
    "            oracle_res = np.array([o[g][metric][model] for o in oracle_acc_list])\n",
    "            synth_res = np.array([s[g][metric][model] for s in synth_acc_list])\n",
    "            aug_res = np.array([a[g][metric][model] for a in aug_acc_list])\n",
    "            test_res = np.array([t[g][metric][model] for t in test_acc_list])\n",
    "            df = pd.concat([df, pd.DataFrame([{\n",
    "                'Group': f\"{idx+1} ({int(round(props[g]*100,0))}%)\",\n",
    "                'Oracle': round(np.mean(oracle_res)*100,2),\n",
    "                'Synthetic': round(np.mean(synth_res)*100,2),\n",
    "                'Augmented': round(np.mean(aug_res)*100,2),\n",
    "                'Test': round(np.mean(test_res)*100,2),\n",
    "            }])], ignore_index=True)\n",
    "            df_std = pd.concat([df_std, pd.DataFrame([{\n",
    "                'Group': f\"{idx+1} ({int(round(props[g]*100,0))}%)\",\n",
    "                'Oracle': round(np.std(oracle_res)*100,2),\n",
    "                'Synthetic': round(np.std(synth_res)*100,2),\n",
    "                'Augmented': round(np.std(aug_res)*100,2),\n",
    "                'Test': round(np.std(test_res)*100,2),\n",
    "            }])], ignore_index=True)\n",
    "        out1 = f\"../results/{dataset_name}_subgroup_shift_ddpm_env_{model}_{metric}.csv\"\n",
    "        out2 = f\"../results/{dataset_name}_subgroup_shift_ddpm_env_std_{model}_{metric}.csv\"\n",
    "        df.to_csv(out1, index=False)\n",
    "        df_std.to_csv(out2, index=False)\n",
    "        print('Saved', out1)\n",
    "        print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3s",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
