{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d7413eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KeOps] Warning : CUDA libraries not found or could not be loaded; Switching to CPU only.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ctgan.synthesizers.ctgan import CTGANSynthesizer\n",
    "from ctgan.synthesizers.tvae import TVAESynthesizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from src.metrics import *\n",
    "from src.metrics import eval_plugin\n",
    "from src.synthesizer import fit_ctgan\n",
    "from src.utils import *\n",
    "\n",
    "use_trained_model = False\n",
    "\n",
    "seed = 42\n",
    "seed_everything(seed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d0950d",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63611646",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split \n",
    "from src.data_loader import load_support_dataset\n",
    "\n",
    "seed = 42  # make sure seed is defined\n",
    "\n",
    "X, y, Data = load_support_dataset()\n",
    "\n",
    "column_metric = \"race\"\n",
    "df = Data  # df includes the column we stratify on\n",
    "\n",
    "# regions: the stratification labels\n",
    "regions = df[column_metric]\n",
    "\n",
    "# First split: train+val vs test\n",
    "splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.65, random_state=seed)\n",
    "train_val_indices, test_indices = next(splitter.split(df, regions))\n",
    "\n",
    "# Use iloc (positional indexing) here\n",
    "regions_train_val = df[column_metric].iloc[train_val_indices]\n",
    "\n",
    "# Second split: train vs val\n",
    "splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=seed)\n",
    "train_indices, val_indices = next(\n",
    "    splitter.split(df.iloc[train_val_indices], regions_train_val)\n",
    ")\n",
    "\n",
    "# Build splits with iloc\n",
    "X_train = df.iloc[train_val_indices[train_indices]]\n",
    "X_test = df.iloc[train_val_indices[val_indices]]\n",
    "X_oracle = df.iloc[test_indices]\n",
    "\n",
    "# Optional: further split off HP set\n",
    "X_train, X_hp = train_test_split(X_train, test_size=0.1, random_state=seed)\n",
    "\n",
    "# Check all splits have the same set of race values\n",
    "assert (\n",
    "    set(X_train[column_metric].unique())\n",
    "    == set(X_test[column_metric].unique())\n",
    "    == set(X_oracle[column_metric].unique())\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdf66c0",
   "metadata": {},
   "source": [
    "# Train Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6978f81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:25<00:00,  8.54s/it]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "ctgans = []\n",
    "trials = []\n",
    "params_list = []\n",
    "\n",
    "# Candidate discrete columns you *wish* to treat as categorical\n",
    "raw_discrete_columns = [\n",
    "    \"sex\",\n",
    "    \"ARF/MOSF w/Sepsis\",\n",
    "    \"COPD\",\n",
    "    \"CHF\",\n",
    "    \"Cirrhosis\",\n",
    "    \"Coma\",\n",
    "    \"Colon Cancer\",\n",
    "    \"Lung Cancer\",\n",
    "    \"MOSF w/Malig\",\n",
    "    \"ARF/MOSF\",\n",
    "    \"Cancer\",\n",
    "    \"num.co\",\n",
    "    \"hday\",\n",
    "    \"diabetes\",\n",
    "    \"dementia\",\n",
    "    \"hrt\",\n",
    "    \"resp\",\n",
    "    \"y\",\n",
    "    \"salary\",\n",
    "    \"race\",\n",
    "]\n",
    "\n",
    "# Keep only those that actually exist in the data\n",
    "discrete_columns = [c for c in raw_discrete_columns if c in X_test.columns]\n",
    "\n",
    "dataset_name = \"support\"\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "hp_sweep = False\n",
    "if use_trained_model == False:\n",
    "    if hp_sweep:\n",
    "        import optuna\n",
    "        from optuna.samplers import TPESampler\n",
    "\n",
    "        # Optimize HPS\n",
    "        def gan_objective(trial):\n",
    "\n",
    "            discrete_columns = [\n",
    "                \"sex\",\n",
    "                \"ARF/MOSF w/Sepsis\",\n",
    "                \"COPD\",\n",
    "                \"CHF\",\n",
    "                \"Cirrhosis\",\n",
    "                \"Coma\",\n",
    "                \"Colon Cancer\",\n",
    "                \"Lung Cancer\",\n",
    "                \"MOSF w/Malig\",\n",
    "                \"ARF/MOSF\",\n",
    "                \"Cancer\",\n",
    "                \"num.co\",\n",
    "                \"hday\",\n",
    "                \"diabetes\",\n",
    "                \"dementia\",\n",
    "                \"hrt\",\n",
    "                \"resp\",\n",
    "                \"y\",\n",
    "                \"salary\",\n",
    "                \"race\",\n",
    "            ]\n",
    "            learning_rate = trial.suggest_categorical(\n",
    "                \"learning_rate\", [2e-4, 2e-5, 2e-6]\n",
    "            )\n",
    "            embedding_dim = trial.suggest_categorical(\"embedding_dim\", [64, 128, 256])\n",
    "            epochs = trial.suggest_categorical(\"epochs\", [200, 300, 500])\n",
    "\n",
    "            ctgan = fit_ctgan(\n",
    "                data=X_test,\n",
    "                epochs=epochs,\n",
    "                learning_rate=learning_rate,\n",
    "                embedding_dim=embedding_dim,\n",
    "                discrete_columns=discrete_columns,\n",
    "            )\n",
    "            D_fake, _ = ctgan.sample(X_hp.shape[0], shift=False)\n",
    "            metric = MaximumMeanDiscrepancy\n",
    "            trial_results = eval_plugin(\n",
    "                metric,\n",
    "                GenericDataLoader(X_hp.astype(float)),\n",
    "                GenericDataLoader(D_fake.astype(float)),\n",
    "            )\n",
    "            trials.append(trial_results)\n",
    "            print(\n",
    "                eval_plugin(\n",
    "                    WassersteinDistance,\n",
    "                    GenericDataLoader(X_hp.astype(float)),\n",
    "                    GenericDataLoader(D_fake.astype(float)),\n",
    "                )\n",
    "            )\n",
    "\n",
    "            print(f\"HPS = Params: {trial.params} | Score: {trial_results[0]}\")\n",
    "            return trial_results[0][\"joint\"]\n",
    "\n",
    "        gan_study = optuna.create_study(direction=\"minimize\", sampler=TPESampler())\n",
    "        gan_study.optimize(gan_objective, show_progress_bar=True, n_trials=10)\n",
    "        print(\"Best parameters:\", gan_study.best_params)\n",
    "\n",
    "        ctgan = fit_ctgan(\n",
    "            data=X_test,\n",
    "            epochs=gan_study.best_params[\"epochs\"],\n",
    "            learning_rate=gan_study.best_params[\"learning_rate\"],\n",
    "            embedding_dim=gan_study.best_params[\"embedding_dim\"],\n",
    "            discrete_columns=discrete_columns,\n",
    "        )\n",
    "        ctgans.append(deepcopy(ctgan))\n",
    "\n",
    "    else:\n",
    "\n",
    "        from copy import deepcopy\n",
    "        from tqdm import tqdm\n",
    "\n",
    "        for i in tqdm(range(10)):\n",
    "\n",
    "            best_params = {\"learning_rate\": 0.0002, \"embedding_dim\": 256, \"epochs\": 100}\n",
    "            ctgan = fit_ctgan(\n",
    "                data=X_test,\n",
    "                epochs=best_params[\"epochs\"],\n",
    "                learning_rate=best_params[\"learning_rate\"],\n",
    "                embedding_dim=best_params[\"embedding_dim\"],\n",
    "                seed=seed,\n",
    "                discrete_columns=discrete_columns,\n",
    "            )\n",
    "            D_fake, _ = ctgan.sample(X_hp.shape[0], shift=False)\n",
    "\n",
    "            trial_results = eval_plugin(\n",
    "                MaximumMeanDiscrepancy,\n",
    "                GenericDataLoader(X_hp.astype(float)),\n",
    "                GenericDataLoader(D_fake.astype(float)),\n",
    "            )\n",
    "            trials.append(trial_results)\n",
    "            params_list.append(best_params)\n",
    "            ctgans.append(deepcopy(ctgan))\n",
    "\n",
    "        # save each ctgan model in ctgan_list\n",
    "        for idx, ctgan_save in enumerate(ctgans):\n",
    "            ctgan_save.save(f\"../models/ctgan_{dataset_name}_{idx+1}\")\n",
    "\n",
    "        trials_list = [trials[idx][0][\"joint\"] for idx in range(len(trials))]\n",
    "        ctgan_idx = trials_list.index(min(trials_list))\n",
    "\n",
    "        ctgan = ctgans[ctgan_idx]\n",
    "\n",
    "        ctgan.save(f\"../models/ctgan_{dataset_name}\")\n",
    "\n",
    "        # pickle best params\n",
    "        with open(f\"../models/ctgan_{dataset_name}_params.pkl\", \"wb\") as f:\n",
    "            pickle.dump(params_list[ctgan_idx], f)\n",
    "\n",
    "\n",
    "else:\n",
    "    # Load best_params\n",
    "    with open(f\"../models/ctgan_{dataset_name}_params.pkl\", \"rb\") as f:\n",
    "        best_params = pickle.load(f)\n",
    "\n",
    "    ctgan = CTGANSynthesizer(\n",
    "        embedding_dim=best_params[\"embedding_dim\"],\n",
    "        generator_dim=(256, 256),\n",
    "        discriminator_dim=(256, 256),\n",
    "        generator_lr=best_params[\"learning_rate\"],\n",
    "        generator_decay=1e-6,\n",
    "        discriminator_lr=best_params[\"learning_rate\"],\n",
    "        discriminator_decay=1e-6,\n",
    "        batch_size=500,\n",
    "        discriminator_steps=1,\n",
    "        log_frequency=True,\n",
    "        verbose=False,\n",
    "        epochs=best_params[\"epochs\"],\n",
    "        pac=10,\n",
    "        cuda=True,\n",
    "    )\n",
    "\n",
    "    ctgan = ctgan.load(f\"../models/ctgan_{dataset_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b99f0de",
   "metadata": {},
   "source": [
    "# Train the downstream predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86a3db92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training baseline models\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model_dict = {\n",
    "    \"mlp\": MLPClassifier(random_state=seed),\n",
    "    \"knn\": KNeighborsClassifier(),\n",
    "    \"dt\": DecisionTreeClassifier(random_state=seed),\n",
    "    \"rf\": RandomForestClassifier(random_state=seed),\n",
    "    \"gbc\": GradientBoostingClassifier(random_state=seed),\n",
    "    \"bag\": BaggingClassifier(random_state=seed),\n",
    "    \"ada\": AdaBoostClassifier(random_state=seed),\n",
    "    \"svm\": SVC(random_state=seed),\n",
    "    \"lr\": LogisticRegression(random_state=seed),\n",
    "}\n",
    "\n",
    "print(\"training baseline models\")\n",
    "\n",
    "trained_model_dict = train_models(X_train, model_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35ff59c",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19e7edbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "from fairlearn.metrics import demographic_parity_ratio as dp_ratio\n",
    "from fairlearn.metrics import equalized_odds_ratio as eo_ratio\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def evaluate_models(models, data, column_metric, sensitive=\"Sex_male\"):\n",
    "    performance = {\"acc\": {}, \"f1\": {}, \"eo\": {}, \"dp\": {}}\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        if data.shape[0] == 0:\n",
    "            performance[\"acc\"][model_name] = 0\n",
    "            performance[\"f1\"][model_name] = 0\n",
    "            performance[\"eo\"][model_name] = 0\n",
    "            performance[\"dp\"][model_name] = 0\n",
    "            continue\n",
    "\n",
    "        y_pred = model.predict(data.drop(\"y\", axis=1))\n",
    "        accuracy = accuracy_score(data[\"y\"], y_pred)\n",
    "        F1 = f1_score(data[\"y\"], y_pred)\n",
    "\n",
    "        try:\n",
    "            eo_score = eo_ratio(\n",
    "                data[\"y\"], y_pred, sensitive_features=data[sensitive].values\n",
    "            )\n",
    "        except:\n",
    "            eo_score = 0\n",
    "\n",
    "        try:\n",
    "            dp_score = dp_ratio(\n",
    "                data[\"y\"], y_pred, sensitive_features=data[sensitive].values\n",
    "            )\n",
    "        except:\n",
    "            dp_score = 0\n",
    "\n",
    "        performance[\"acc\"][model_name] = accuracy\n",
    "        performance[\"f1\"][model_name] = F1\n",
    "        performance[\"eo\"][model_name] = eo_score\n",
    "        performance[\"dp\"][model_name] = dp_score\n",
    "\n",
    "    return performance\n",
    "\n",
    "\n",
    "def run_analysis(\n",
    "    column_metric,\n",
    "    ctgan,\n",
    "    Data,\n",
    "    X_train,\n",
    "    X_test,\n",
    "    X_oracle,\n",
    "    trained_model_dict,\n",
    "    random_state=0,\n",
    "    n_samples=1000,\n",
    "):\n",
    "    # Initialization\n",
    "    groups = list(np.unique(Data[column_metric]))\n",
    "\n",
    "    X_train, X_test = train_test_split(\n",
    "        X_train, test_size=0.2, random_state=random_state\n",
    "    )\n",
    "    test_dataset = deepcopy(X_test)\n",
    "\n",
    "    (\n",
    "        test_results,\n",
    "        test_samples,\n",
    "        oracle_results,\n",
    "        oracle_samples,\n",
    "        synth_results,\n",
    "        synth_samples,\n",
    "        aug_results,\n",
    "        aug_samples,\n",
    "    ) = ({}, {}, {}, {}, {}, {}, {}, {})\n",
    "\n",
    "    for group in tqdm(groups):\n",
    "        total_samples = (\n",
    "            X_test[X_test[column_metric] == 0].shape[0] if group == 0 else n_samples\n",
    "        )\n",
    "        total_samples = n_samples\n",
    "        test_data = X_test[X_test[column_metric] == group]\n",
    "        oracle_data = X_oracle[X_oracle[column_metric] == group]\n",
    "\n",
    "        # Dtest\n",
    "        test_results[group], test_samples[group] = (\n",
    "            evaluate_models(trained_model_dict, test_data, column_metric),\n",
    "            test_data.shape[0],\n",
    "        )\n",
    "        oracle_results[group], oracle_samples[group] = (\n",
    "            evaluate_models(trained_model_dict, oracle_data, column_metric),\n",
    "            oracle_data.shape[0],\n",
    "        )\n",
    "\n",
    "        # Synthetic data sampling\n",
    "        synth_data, _ = ctgan.sample(\n",
    "            1, shift=False, condition_column=column_metric, condition_value=group\n",
    "        )\n",
    "        count = 0\n",
    "        while synth_data.shape[0] <= total_samples:\n",
    "            tmp_df = ctgan.sample(\n",
    "                n_samples,\n",
    "                shift=False,\n",
    "                condition_column=column_metric,\n",
    "                condition_value=group,\n",
    "            )[0]\n",
    "            synth_data = synth_data.append(tmp_df[tmp_df[column_metric] == group])\n",
    "            count += 1\n",
    "        synth_results[group], synth_samples[group] = (\n",
    "            evaluate_models(trained_model_dict, synth_data, column_metric),\n",
    "            synth_data.shape[0],\n",
    "        )\n",
    "\n",
    "        # Augmented data evaluation\n",
    "        aug_data = pd.concat([test_data, synth_data])\n",
    "        aug_results[group], aug_samples[group] = (\n",
    "            evaluate_models(trained_model_dict, aug_data, column_metric),\n",
    "            aug_data.shape[0],\n",
    "        )\n",
    "\n",
    "    return (\n",
    "        test_results,\n",
    "        test_samples,\n",
    "        oracle_results,\n",
    "        oracle_samples,\n",
    "        synth_results,\n",
    "        synth_samples,\n",
    "        aug_results,\n",
    "        aug_samples,\n",
    "        test_dataset,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e71d38",
   "metadata": {},
   "source": [
    "# Run analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3496ebb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:21<00:00,  5.26s/it]\n",
      "100%|██████████| 4/4 [00:21<00:00,  5.39s/it]\n",
      "100%|██████████| 4/4 [00:21<00:00,  5.34s/it]\n",
      "100%|██████████| 4/4 [00:29<00:00,  7.37s/it]\n",
      "100%|██████████| 4/4 [00:30<00:00,  7.51s/it]\n",
      "100%|██████████| 5/5 [02:03<00:00, 24.70s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "test_acc_list = []\n",
    "test_samples_list = []\n",
    "oracle_acc_list = []\n",
    "oracle_samples_list = []\n",
    "synth_acc_list = []\n",
    "synth_samples_list = []\n",
    "aug_acc_list = []\n",
    "aug_samples_list = []\n",
    "final_test_dataset = []\n",
    "\n",
    "\n",
    "n_runs = 5\n",
    "ns = 5000\n",
    "\n",
    "for i in tqdm(range(n_runs)):\n",
    "\n",
    "    done = False\n",
    "    tries = 0\n",
    "\n",
    "    while done == False:\n",
    "        try:\n",
    "            (\n",
    "                test_final,\n",
    "                test_samples,\n",
    "                oracle_final,\n",
    "                oracle_samples,\n",
    "                synth_final,\n",
    "                synth_samples,\n",
    "                aug_final,\n",
    "                aug_samples,\n",
    "                test_dataset,\n",
    "            ) = run_analysis(\n",
    "                column_metric=column_metric,\n",
    "                Data=Data,\n",
    "                X_train=X_train,\n",
    "                X_test=X_test,\n",
    "                X_oracle=X_oracle,\n",
    "                ctgan=ctgan,\n",
    "                trained_model_dict=trained_model_dict,\n",
    "                random_state=i * 100,\n",
    "                n_samples=ns,\n",
    "            )\n",
    "            done = True\n",
    "            final_test_dataset.append(test_dataset)\n",
    "        except Exception:\n",
    "            import traceback\n",
    "\n",
    "            print(traceback.format_exc())\n",
    "            tries += 1\n",
    "\n",
    "            if tries > 5:\n",
    "                done = True\n",
    "            continue\n",
    "\n",
    "    test_acc_list.append(test_final)\n",
    "    test_samples_list.append(test_samples)\n",
    "    oracle_acc_list.append(oracle_final)\n",
    "    oracle_samples_list.append(oracle_samples)\n",
    "    synth_acc_list.append(synth_final)\n",
    "    synth_samples_list.append(synth_samples)\n",
    "    aug_acc_list.append(aug_final)\n",
    "    aug_samples_list.append(aug_samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2247632a",
   "metadata": {},
   "source": [
    "# Process results & save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a0a0464",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 1100/1100 [12:05,  1.52it/s, step size=2.02e-04, acc. prob=0.958]\n",
      "Sample: 100%|██████████| 1100/1100 [10:46,  1.70it/s, step size=5.02e-04, acc. prob=0.905]\n",
      "Sample: 100%|██████████| 1100/1100 [06:41,  2.74it/s, step size=5.28e-04, acc. prob=0.950]\n",
      "Sample: 100%|██████████| 1100/1100 [19:12,  1.05s/it, step size=1.32e-04, acc. prob=0.933]\n",
      "Sample: 100%|██████████| 1100/1100 [10:11,  1.80it/s, step size=3.80e-04, acc. prob=0.907]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_51767/1918830799.py\", line 104, in <module>\n",
      "    blm_res.append(accuracy_score(y_true_group, y_pred_group))\n",
      "  File \"/home/dhanush/anaconda3/envs/3s/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 214, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/dhanush/anaconda3/envs/3s/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 220, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/dhanush/anaconda3/envs/3s/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 93, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and unknown targets\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_51767/1918830799.py\", line 61, in <module>\n",
      "    [\n",
      "  File \"/tmp/ipykernel_51767/1918830799.py\", line 62, in <listcomp>\n",
      "    mylist[i][group][metric][model_name]\n",
      "KeyError: 4\n",
      "\n",
      "IM EXCEPTING 4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from brmp import brm\n",
    "from brmp.numpyro_backend import backend as numpyro\n",
    "from brmp.pyro_backend import backend as pyro_backend\n",
    "from copy import deepcopy\n",
    "\n",
    "metrics = [\"acc\"]\n",
    "models = list(trained_model_dict.keys())\n",
    "\n",
    "models = ['rf']\n",
    "\n",
    "\n",
    "X_test_new = deepcopy(final_test_dataset[0])\n",
    "\n",
    "for metric in metrics:\n",
    "\n",
    "    for model in models:\n",
    "\n",
    "        try:\n",
    "            blm = []\n",
    "            for i in range(5):\n",
    "                seed = i * 100\n",
    "                xt = deepcopy(X_train)\n",
    "                _, X_test = train_test_split(xt, test_size=0.2, random_state=seed)\n",
    "                X_test[\"S\"] = np.max(\n",
    "                    trained_model_dict[model].predict_proba(X_test.drop(\"y\", axis=1)),\n",
    "                    axis=1,\n",
    "                )\n",
    "                model3 = brm(\n",
    "                    \"S ~ race + salary + sex + age + ph + glucose + sod + crea + bili + alb + wblc + y\",\n",
    "                    X_test,\n",
    "                )\n",
    "                fit3 = model3.fit(\n",
    "                    backend=pyro_backend, seed=seed, iter=1000, warmup=100\n",
    "                )\n",
    "                scores3 = fit3.fitted(what=\"sample\", data=None, seed=seed)\n",
    "                blm.append(scores3)\n",
    "            blm = np.array(blm)\n",
    "\n",
    "            props = [\n",
    "                count / np.sum(np.unique(Data[column_metric], return_counts=True)[1])\n",
    "                for count in np.unique(Data[column_metric], return_counts=True)[1]\n",
    "            ]\n",
    "\n",
    "            groups = np.sort(list(X_test[column_metric].unique()))\n",
    "\n",
    "            for model_name in [model]:\n",
    "                print(model_name)\n",
    "                data_list = []\n",
    "                idx = 0\n",
    "\n",
    "                df = pd.DataFrame(columns=[\"Group\", \"3S\", \"3S+\", \"BLM\", \"Dtest\"])\n",
    "                df_std = pd.DataFrame(columns=[\"Group\", \"3S\", \"3S+\", \"BLM\", \"Dtest\"])\n",
    "\n",
    "                for group in np.argsort(props)[::-1]:\n",
    "           \n",
    "                    group = group + 1\n",
    "                    idx += 1\n",
    "                    mylist = oracle_acc_list\n",
    "                    oracle_res = np.array(\n",
    "                        [\n",
    "                            mylist[i][group][metric][model_name]\n",
    "                            for i in range(len(mylist))\n",
    "                        ]\n",
    "                    )\n",
    "\n",
    "                    mylist = synth_acc_list\n",
    "                    synth_res = np.array(\n",
    "                        [\n",
    "                            mylist[i][group][metric][model_name]\n",
    "                            for i in range(len(mylist))\n",
    "                        ]\n",
    "                    )\n",
    "\n",
    "                    mylist = test_acc_list\n",
    "                    test_res = np.array(\n",
    "                        [\n",
    "                            mylist[i][group][metric][model_name]\n",
    "                            for i in range(len(mylist))\n",
    "                        ]\n",
    "                    )\n",
    "\n",
    "                    mylist = aug_acc_list\n",
    "                    aug_res = np.array(\n",
    "                        [\n",
    "                            mylist[i][group][metric][model_name]\n",
    "                            for i in range(len(mylist))\n",
    "                        ]\n",
    "                    )\n",
    "\n",
    "                    try:\n",
    "                        # blm\n",
    "                        blm_res = []\n",
    "                        for i in range(5):\n",
    "                            y_pred = (np.mean(blm[i], axis=0) > 0.75).astype(int) # confident predictions\n",
    "                            group_ids = np.argwhere(\n",
    "                                np.array(X_test_new[column_metric] == group).astype(int)\n",
    "                                == 1\n",
    "                            )\n",
    "                            y_pred_group = y_pred[group_ids]\n",
    "                            y_true_group = X_test_new[\n",
    "                                X_test_new[column_metric] == group\n",
    "                            ][\"y\"]\n",
    "                            blm_res.append(accuracy_score(y_true_group, y_pred_group))\n",
    "\n",
    "                        blm_res = np.array(blm_res)\n",
    "\n",
    "\n",
    "                        mydict = {\n",
    "                            \"Group\": f\"{idx} ({int(round(props[group-1]*100,0))}%)\",\n",
    "                            \"3S\": round(\n",
    "                                np.mean(np.abs(oracle_res - synth_res)) * 100, 2\n",
    "                            ),\n",
    "                            \"3S+\": round(\n",
    "                                np.mean(np.abs(oracle_res - aug_res)) * 100, 2\n",
    "                            ),\n",
    "                            \"BLM\": round(\n",
    "                                np.mean(np.abs(oracle_res - blm_res)) * 100, 2\n",
    "                            ),\n",
    "                            \"Dtest\": round(\n",
    "                                np.mean(np.abs(oracle_res - test_res)) * 100, 2\n",
    "                            ),\n",
    "                        }\n",
    "                        df = df.append(mydict, ignore_index=True)\n",
    "\n",
    "                        mydict = {\n",
    "                            \"Group\": f\"{idx} ({int(round(props[group-1]*100,0))}%)\",\n",
    "                            \"3S\": round(\n",
    "                                np.std(np.abs(oracle_res - synth_res)) * 100, 2\n",
    "                            ),\n",
    "                            \"3S+\": round(np.std(np.abs(oracle_res - aug_res)) * 100, 2),\n",
    "                            \"BLM\": round(np.std(np.abs(oracle_res - blm_res)) * 100, 2),\n",
    "                            \"Dtest\": round(\n",
    "                                np.std(np.abs(oracle_res - test_res)) * 100, 2\n",
    "                            ),\n",
    "                        }\n",
    "                        df_std = df_std.append(mydict, ignore_index=True)\n",
    "\n",
    "                    except Exception:\n",
    "                        import traceback\n",
    "\n",
    "                        print(traceback.format_exc())\n",
    "                        continue\n",
    "\n",
    "            df.to_csv(f\"../results/{dataset_name}_{model}_{metric}.csv\")\n",
    "            df_std.to_csv(f'../results/{dataset_name}_std_{model}_{metric}.csv')\n",
    "\n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "\n",
    "            print(traceback.format_exc())\n",
    "            print(\"IM EXCEPTING\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2f030c",
   "metadata": {},
   "source": [
    "# Coverage helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69c5f592",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import pandas as pd\n",
    "from brmp import brm\n",
    "from brmp.numpyro_backend import backend as numpyro\n",
    "from brmp.pyro_backend import backend as pyro_backend\n",
    "\n",
    "\n",
    "def get_group(X_test, column_metric, groups, test_group=\"small\"):\n",
    "    smallest_group = 0\n",
    "    gsizes = []\n",
    "    for idx, group in enumerate(groups):\n",
    "        gsizes.append(X_test[X_test[column_metric] == group].shape[0])\n",
    "\n",
    "    print(gsizes)\n",
    "    ns = 10\n",
    "    for idx, group in enumerate(groups):\n",
    "\n",
    "        if test_group == \"small\":\n",
    "            if idx == 0:\n",
    "                size_smallest_group = X_test[X_test[column_metric] == 0].shape[0]\n",
    "                smallest_group = group\n",
    "                if size_smallest_group < ns:\n",
    "                    size_smallest_group = 99999\n",
    "            else:\n",
    "                if (\n",
    "                    X_test[X_test[column_metric] == group].shape[0]\n",
    "                    < size_smallest_group\n",
    "                ):\n",
    "                    if X_test[X_test[column_metric] == group].shape[0] > ns:\n",
    "                        size_smallest_group = X_test[\n",
    "                            X_test[column_metric] == group\n",
    "                        ].shape[0]\n",
    "                        smallest_group = group\n",
    "\n",
    "        else:\n",
    "            if idx == 0:\n",
    "                size_smallest_group = X_test[X_test[column_metric] == 0].shape[0]\n",
    "                smallest_group = group\n",
    "            else:\n",
    "                if (\n",
    "                    X_test[X_test[column_metric] == group].shape[0]\n",
    "                    > size_smallest_group\n",
    "                ):\n",
    "                    size_smallest_group = X_test[X_test[column_metric] == group].shape[\n",
    "                        0\n",
    "                    ]\n",
    "                    smallest_group = group\n",
    "\n",
    "    return smallest_group\n",
    "\n",
    "\n",
    "def uncertainty(\n",
    "    column_metric,\n",
    "    ctgans,\n",
    "    X_train,\n",
    "    X_test,\n",
    "    X_oracle,\n",
    "    trained_model_dict,\n",
    "    random_state=0,\n",
    "    n_samples=5000,\n",
    "    test_group=\"small\",\n",
    "):\n",
    "    from sklearn.metrics import f1_score\n",
    "    from fairlearn.metrics import equalized_odds_ratio as eo_ratio\n",
    "    from fairlearn.metrics import demographic_parity_ratio as dp_ratio\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    score = \"acc\"\n",
    "\n",
    "    groups = list(np.unique(Data[column_metric]))\n",
    "    orig_random_state = deepcopy(random_state)\n",
    "\n",
    "    coverage_dict = {}\n",
    "    width_dict = {}\n",
    "    excess_dict = {}\n",
    "    deficet_dict = {}\n",
    "\n",
    "    for model in [\"rf\"]:\n",
    "\n",
    "        random_state = orig_random_state\n",
    "\n",
    "\n",
    "        try:\n",
    "            trained_model_dict[model].predict_proba(X_train.drop(\"y\", axis=1))\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        test_coverage = []\n",
    "        synth_coverage = []\n",
    "        synth_coverage5 = []\n",
    "        synth_coverage10 = []\n",
    "        blm_coverage = []\n",
    "\n",
    "        test_width = []\n",
    "        synth_width = []\n",
    "        synth_width5 = []\n",
    "        synth_width10 = []\n",
    "        blm_width = []\n",
    "\n",
    "        test_excess = []\n",
    "        synth_excess = []\n",
    "        synth_excess5 = []\n",
    "        synth_excess10 = []\n",
    "        blm_excess = []\n",
    "\n",
    "        test_deficet = []\n",
    "        synth_deficet = []\n",
    "        synth_deficet5 = []\n",
    "        synth_deficet10 = []\n",
    "        blm_deficet = []\n",
    "\n",
    "        error_test = []\n",
    "        error_synth = []\n",
    "\n",
    "        for random_state in tqdm(range(20)):\n",
    "\n",
    "         \n",
    "            _, X_test = train_test_split(\n",
    "                X_train, test_size=0.2, random_state=random_state\n",
    "            )\n",
    "\n",
    "            deepcopy(X_test)\n",
    "\n",
    "          \n",
    "            blm_accs = {}\n",
    "\n",
    "        \n",
    "            smallest_group = get_group(\n",
    "                X_test, column_metric, groups, test_group=\"small\"\n",
    "            )\n",
    "            print(f\"Smallest group: {smallest_group}, random_state: {random_state}\")\n",
    "\n",
    "            for group in groups:\n",
    "\n",
    "                if group != smallest_group:\n",
    "                    continue\n",
    "\n",
    "                # n_samples = 1000\n",
    "                if group == 0:\n",
    "                    total_samples = X_test[X_test[column_metric] == 0].shape[0]\n",
    "                else:\n",
    "                    total_samples = n_samples\n",
    "\n",
    "                test_data = X_test[X_test[column_metric] == group]\n",
    "\n",
    "                oracle_data = X_oracle[X_oracle[column_metric] == group]\n",
    "\n",
    "                print(f\"TEST SIZE {group} - {test_data.shape[0]}\")\n",
    "\n",
    "                if test_data.shape[0] == 0:\n",
    "                    accuracy = 0\n",
    "\n",
    "                else:\n",
    "                    slack = 0.025  # slack for the confidence interval\n",
    "                    clf = model_dict[model]\n",
    "\n",
    "                    ############################################################\n",
    "                    # Oracle\n",
    "                    ############################################################\n",
    "                    y_pred = clf.predict(oracle_data.drop(\"y\", axis=1))\n",
    "                    accuracy_oracle = accuracy_score(oracle_data[\"y\"], y_pred)\n",
    "                    print(oracle_data.shape, accuracy_oracle)\n",
    "\n",
    "                    ############################################################\n",
    "                    # Bootstrap Dtest\n",
    "                    ############################################################\n",
    "                    y_pred = clf.predict(test_data.drop(\"y\", axis=1))\n",
    "                    accuracy = accuracy_score(test_data[\"y\"], y_pred)\n",
    "                    R = 1000\n",
    "                    confidence_level = 0.95\n",
    "                    metric = accuracy_score\n",
    "                    scores = bootstrap(\n",
    "                        test_data[\"y\"].values.reshape(-1, 1),\n",
    "                        y_pred.reshape(-1, 1),\n",
    "                        metric,\n",
    "                        R,\n",
    "                    )\n",
    "                    bottom_test, top_test = confidence_intervals(\n",
    "                        scores, confidence_level\n",
    "                    )\n",
    "                    score = 0\n",
    "                    if (\n",
    "                        accuracy_oracle >= bottom_test.values - slack\n",
    "                        and accuracy_oracle <= top_test.values + slack\n",
    "                    ):\n",
    "                        score = 1\n",
    "                    test_coverage.append(score)\n",
    "                    error_test.append(accuracy_oracle - accuracy)\n",
    "                    excess, deficet, width = compute_interval_metrics(\n",
    "                        lb=bottom_test.values - slack,\n",
    "                        ub=top_test.values + slack,\n",
    "                        true=accuracy_oracle,\n",
    "                    )\n",
    "                    test_width.append(width)\n",
    "                    if excess != -9999:\n",
    "                        test_excess.append(excess)\n",
    "                    if deficet != -9999:\n",
    "                        test_deficet.append(deficet)\n",
    "\n",
    "                    ############################################################\n",
    "                    # MBM Interval\n",
    "                    ############################################################\n",
    "                    X_test_new = deepcopy(X_test)\n",
    "                    X_test_new[\"S\"] = trained_model_dict[model].predict_proba(\n",
    "                        X_test_new.drop(\"y\", axis=1)\n",
    "                    )[:, 1]\n",
    "\n",
    "                    model3 = brm(\n",
    "                        \"S ~ race + salary + sex + age + ph + glucose + sod + crea + bili + alb + wblc + y\",\n",
    "                        X_test_new,\n",
    "                    )\n",
    "                    fit3 = model3.fit(\n",
    "                        backend=pyro_backend, seed=0, iter=1000, warmup=100\n",
    "                    )\n",
    "                    myscores = fit3.fitted(what=\"sample\", data=None, seed=0)\n",
    "\n",
    "                    blm_accs = []\n",
    "                    for j in range(100):\n",
    "                        scores3 = np.array(\n",
    "                            [\n",
    "                                myscores[np.random.randint(1000, size=1), i]\n",
    "                                for i in range(myscores.shape[1])\n",
    "                            ]\n",
    "                        )\n",
    "                        y_pred = (scores3 > 0.75).astype(int).flatten()\n",
    "                        group_ids = np.argwhere(\n",
    "                            np.array(X_test_new[column_metric] == group).astype(int)\n",
    "                            == 1\n",
    "                        )\n",
    "                        y_pred_group = y_pred[group_ids]\n",
    "                        acc = accuracy_score(test_data[\"y\"], y_pred_group)\n",
    "                        blm_accs.append(acc)\n",
    "\n",
    "                    mean_blm_acc = np.mean(blm_accs)\n",
    "                    std_blm_acc = np.std(blm_accs)\n",
    "                    bottom_blm = mean_blm_acc - 1.96 * std_blm_acc\n",
    "                    top_blm = mean_blm_acc + 1.96 * std_blm_acc\n",
    "\n",
    "                    score = 0\n",
    "                    if (\n",
    "                        accuracy_oracle >= bottom_blm - slack\n",
    "                        and accuracy_oracle <= top_blm + slack\n",
    "                    ):\n",
    "                        score = 1\n",
    "                    blm_coverage.append(score)\n",
    "                    excess, deficet, width = compute_interval_metrics(\n",
    "                        lb=bottom_blm - slack, ub=top_blm + slack, true=accuracy_oracle\n",
    "                    )\n",
    "                    blm_width.append(width)\n",
    "                    if excess != -9999:\n",
    "                        blm_excess.append(excess)\n",
    "                    if deficet != -9999:\n",
    "                        blm_deficet.append(deficet)\n",
    "\n",
    "                    ############################################################\n",
    "                    # 3S (k=1)\n",
    "                    ############################################################\n",
    "                    syn_accs = []\n",
    "                    for i in range(100):\n",
    "                        shift_df, _ = ctgans[0].sample(\n",
    "                            1,\n",
    "                            shift=False,\n",
    "                            condition_column=column_metric,\n",
    "                            condition_value=group,\n",
    "                        )\n",
    "                        count = 0\n",
    "                        while shift_df.shape[0] <= total_samples:\n",
    "                            generated_tmp, _ = ctgans[0].sample(\n",
    "                                n_samples,\n",
    "                                shift=False,\n",
    "                                condition_column=column_metric,\n",
    "                                condition_value=group,\n",
    "                            )\n",
    "                            tmp_df = generated_tmp[\n",
    "                                generated_tmp[column_metric] == group\n",
    "                            ]\n",
    "                            shift_df = shift_df.append(tmp_df)\n",
    "                            count += 1\n",
    "\n",
    "                        syn_data = shift_df[shift_df[column_metric] == group]\n",
    "                        y_pred = clf.predict(syn_data.drop(\"y\", axis=1))\n",
    "                        accuracy = accuracy_score(syn_data[\"y\"], y_pred)\n",
    "                        syn_accs.append(accuracy)\n",
    "\n",
    "                    mean_syn_acc = np.mean(syn_accs)\n",
    "                    std_syn_acc = np.std(syn_accs)\n",
    "                    bottom_syn = mean_syn_acc - 1.96 * std_syn_acc\n",
    "                    top_syn = mean_syn_acc + 1.96 * std_syn_acc\n",
    "\n",
    "                    ############################################################\n",
    "                    # 3S (k=5)\n",
    "                    ############################################################\n",
    "                    syn_accs5 = []\n",
    "                    for ctgan in ctgans[0:5]:\n",
    "                        shift_df, _ = ctgan.sample(\n",
    "                            1,\n",
    "                            shift=False,\n",
    "                            condition_column=column_metric,\n",
    "                            condition_value=group,\n",
    "                        )\n",
    "\n",
    "                        count = 0\n",
    "                        while shift_df.shape[0] <= total_samples:\n",
    "                            generated_tmp, _ = ctgan.sample(\n",
    "                                n_samples,\n",
    "                                shift=False,\n",
    "                                condition_column=column_metric,\n",
    "                                condition_value=group,\n",
    "                            )\n",
    "                            tmp_df = generated_tmp[\n",
    "                                generated_tmp[column_metric] == group\n",
    "                            ]\n",
    "                            shift_df = shift_df.append(tmp_df)\n",
    "                            count += 1\n",
    "\n",
    "                        syn_data = shift_df[shift_df[column_metric] == group]\n",
    "                        y_pred = clf.predict(syn_data.drop(\"y\", axis=1))\n",
    "                        accuracy = accuracy_score(syn_data[\"y\"], y_pred)\n",
    "                        syn_accs5.append(accuracy)\n",
    "\n",
    "                    mean_syn_acc = np.mean(syn_accs5)\n",
    "                    std_syn_acc = np.std(syn_accs5)\n",
    "                    bottom_syn5 = mean_syn_acc - 1.96 * std_syn_acc\n",
    "                    top_syn5 = mean_syn_acc + 1.96 * std_syn_acc\n",
    "\n",
    "                    ############################################################\n",
    "                    # 3S (k=10)\n",
    "                    ############################################################\n",
    "                    syn_accs10 = []\n",
    "                    for ctgan in ctgans:\n",
    "                        shift_df, _ = ctgan.sample(\n",
    "                            1,\n",
    "                            shift=False,\n",
    "                            condition_column=column_metric,\n",
    "                            condition_value=group,\n",
    "                        )\n",
    "\n",
    "                        count = 0\n",
    "                        while shift_df.shape[0] <= total_samples:\n",
    "                            generated_tmp, _ = ctgan.sample(\n",
    "                                n_samples,\n",
    "                                shift=False,\n",
    "                                condition_column=column_metric,\n",
    "                                condition_value=group,\n",
    "                            )\n",
    "                            tmp_df = generated_tmp[\n",
    "                                generated_tmp[column_metric] == group\n",
    "                            ]\n",
    "                            shift_df = shift_df.append(tmp_df)\n",
    "                            count += 1\n",
    "\n",
    "                        syn_data = shift_df[shift_df[column_metric] == group]\n",
    "                        y_pred = clf.predict(syn_data.drop(\"y\", axis=1))\n",
    "                        accuracy = accuracy_score(syn_data[\"y\"], y_pred)\n",
    "                        syn_accs10.append(accuracy)\n",
    "\n",
    "                    mean_syn_acc = np.mean(syn_accs10)\n",
    "                    std_syn_acc = np.std(syn_accs10)\n",
    "                    error_synth.append(accuracy_oracle - mean_syn_acc)\n",
    "                    bottom_syn10 = mean_syn_acc - 1.96 * std_syn_acc\n",
    "                    top_syn10 = mean_syn_acc + 1.96 * std_syn_acc\n",
    "\n",
    "                    # compute if the accuracy_oracle is within the confidence interval of the accuracy\n",
    "                    score = 0\n",
    "             \n",
    "                    if (\n",
    "                        accuracy_oracle >= bottom_syn - slack\n",
    "                        and accuracy_oracle <= top_syn + slack\n",
    "                    ):\n",
    "                        score = 1\n",
    "\n",
    "                    synth_coverage.append(score)\n",
    "                    excess, deficet, width = compute_interval_metrics(\n",
    "                        lb=bottom_syn - slack, ub=top_syn + slack, true=accuracy_oracle\n",
    "                    )\n",
    "                    synth_width.append(width)\n",
    "                    if excess != -9999:\n",
    "                        synth_excess.append(excess)\n",
    "                    if deficet != -9999:\n",
    "                        synth_deficet.append(deficet)\n",
    "\n",
    "                    score = 0\n",
    "                    \n",
    "                    if (\n",
    "                        accuracy_oracle >= bottom_syn5 - slack\n",
    "                        and accuracy_oracle <= top_syn5 + slack\n",
    "                    ):\n",
    "                        score = 1\n",
    "                    synth_coverage5.append(score)\n",
    "                    excess, deficet, width = compute_interval_metrics(\n",
    "                        lb=bottom_syn5 - slack,\n",
    "                        ub=top_syn5 + slack,\n",
    "                        true=accuracy_oracle,\n",
    "                    )\n",
    "                    synth_width5.append(width)\n",
    "                    if excess != -9999:\n",
    "                        synth_excess5.append(excess)\n",
    "                    if deficet != -9999:\n",
    "                        synth_deficet5.append(deficet)\n",
    "\n",
    "                    score = 0\n",
    "                    \n",
    "                    if (\n",
    "                        accuracy_oracle >= bottom_syn10 - slack\n",
    "                        and accuracy_oracle <= top_syn10 + slack\n",
    "                    ):\n",
    "                        score = 1\n",
    "                    synth_coverage10.append(score)\n",
    "                    excess, deficet, width = compute_interval_metrics(\n",
    "                        lb=bottom_syn10 - slack,\n",
    "                        ub=top_syn10 + slack,\n",
    "                        true=accuracy_oracle,\n",
    "                    )\n",
    "                    synth_width10.append(width)\n",
    "                    if excess != -9999:\n",
    "                        synth_excess10.append(excess)\n",
    "                    if deficet != -9999:\n",
    "                        synth_deficet10.append(deficet)\n",
    "\n",
    "        mean_test_coverage = np.mean(test_coverage)\n",
    "        mean_blm_coverage = np.mean(blm_coverage)\n",
    "        mean_synth_coverage = np.mean(synth_coverage)\n",
    "        mean_synth_coverage5 = np.mean(synth_coverage5)\n",
    "        mean_synth_coverage10 = np.mean(synth_coverage10)\n",
    "        np.mean(error_test)\n",
    "        np.mean(error_synth)\n",
    "\n",
    "        # mean for width for synth, synth2, synth3, test, mbm\n",
    "        mean_synth_width = np.mean(synth_width)\n",
    "        mean_synth_width5 = np.mean(synth_width5)\n",
    "        mean_synth_width10 = np.mean(synth_width10)\n",
    "        mean_test_width = np.mean(test_width)\n",
    "        mean_blm_width = np.mean(blm_width)\n",
    "\n",
    "        # excess for width for synth, synth2, synth3, test, mbm\n",
    "        mean_synth_excess = np.mean(synth_excess)\n",
    "        mean_synth_excess5 = np.mean(synth_excess5)\n",
    "        mean_synth_excess10 = np.mean(synth_excess10)\n",
    "        mean_test_excess = np.mean(test_excess)\n",
    "        mean_blm_excess = np.mean(blm_excess)\n",
    "\n",
    "        # mean for excess for synth, synth2, synth3, test, mbm\n",
    "        mean_synth_deficet = np.mean(synth_deficet)\n",
    "        mean_synth_deficet5 = np.mean(synth_deficet5)\n",
    "        mean_synth_deficet10 = np.mean(synth_deficet10)\n",
    "        mean_test_deficet = np.mean(test_deficet)\n",
    "        mean_blm_deficet = np.mean(blm_deficet)\n",
    "\n",
    "        # coverage dict\n",
    "        coverage_dict[model] = {\n",
    "            \"test\": mean_test_coverage,\n",
    "            \"synth\": mean_synth_coverage,\n",
    "            \"synth2\": mean_synth_coverage5,\n",
    "            \"synth3\": mean_synth_coverage10,\n",
    "            \"MBM\": mean_blm_coverage,\n",
    "        }\n",
    "\n",
    "        # width dict\n",
    "        width_dict[model] = {\n",
    "            \"test\": mean_test_width,\n",
    "            \"synth\": mean_synth_width,\n",
    "            \"synth2\": mean_synth_width5,\n",
    "            \"synth3\": mean_synth_width10,\n",
    "            \"MBM\": mean_blm_width,\n",
    "        }\n",
    "\n",
    "        # excess dict\n",
    "        excess_dict[model] = {\n",
    "            \"test\": mean_test_excess,\n",
    "            \"synth\": mean_synth_excess,\n",
    "            \"synth2\": mean_synth_excess5,\n",
    "            \"synth3\": mean_synth_excess10,\n",
    "            \"MBM\": mean_blm_excess,\n",
    "        }\n",
    "\n",
    "        # deficet dict\n",
    "        deficet_dict[model] = {\n",
    "            \"test\": mean_test_deficet,\n",
    "            \"synth\": mean_synth_deficet,\n",
    "            \"synth2\": mean_synth_deficet5,\n",
    "            \"synth3\": mean_synth_deficet10,\n",
    "            \"MBM\": mean_blm_deficet,\n",
    "        }\n",
    "\n",
    "    return coverage_dict, width_dict, excess_dict, deficet_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e3e773",
   "metadata": {},
   "source": [
    "# Coverage helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6077ebd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[236, 56, 0, 14]\n",
      "Smallest group: 3.0, random_state: 0\n",
      "TEST SIZE 3.0 - 14\n",
      "(140, 41) 0.7928571428571428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 1100/1100 [06:57,  2.63it/s, step size=4.42e-04, acc. prob=0.952]\n",
      "  5%|▌         | 1/20 [14:15<4:31:00, 855.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[247, 48, 4, 7]\n",
      "Smallest group: 1.0, random_state: 1\n",
      "TEST SIZE 1.0 - 48\n",
      "(638, 41) 0.7633228840125392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 1100/1100 [05:03,  3.63it/s, step size=8.02e-04, acc. prob=0.883]\n",
      " 10%|█         | 2/20 [21:37<3:03:39, 612.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[242, 52, 4, 8]\n",
      "Smallest group: 1.0, random_state: 2\n",
      "TEST SIZE 1.0 - 52\n",
      "(638, 41) 0.7633228840125392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 1100/1100 [02:15,  8.10it/s, step size=9.58e-04, acc. prob=0.306]\n",
      " 15%|█▌        | 3/20 [26:12<2:09:46, 458.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[252, 40, 1, 13]\n",
      "Smallest group: 3.0, random_state: 3\n",
      "TEST SIZE 3.0 - 13\n",
      "(140, 41) 0.7928571428571428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 1100/1100 [04:13,  4.34it/s, step size=9.93e-04, acc. prob=0.879]\n",
      " 20%|██        | 4/20 [38:10<2:29:33, 560.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[242, 54, 5, 5]\n",
      "Smallest group: 1.0, random_state: 4\n",
      "TEST SIZE 1.0 - 54\n",
      "(638, 41) 0.7633228840125392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 1100/1100 [08:55,  2.05it/s, step size=2.50e-04, acc. prob=0.952]\n",
      " 25%|██▌       | 5/20 [49:34<2:31:16, 605.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[243, 50, 1, 12]\n",
      "Smallest group: 3.0, random_state: 5\n",
      "TEST SIZE 3.0 - 12\n",
      "(140, 41) 0.7928571428571428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 1100/1100 [07:11,  2.55it/s, step size=3.89e-04, acc. prob=0.962]\n",
      " 30%|███       | 6/20 [1:04:40<2:45:04, 707.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[232, 57, 2, 15]\n",
      "Smallest group: 3.0, random_state: 6\n",
      "TEST SIZE 3.0 - 15\n",
      "(140, 41) 0.7928571428571428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 1100/1100 [04:19,  4.23it/s, step size=7.28e-04, acc. prob=0.795]\n",
      " 35%|███▌      | 7/20 [1:17:09<2:36:14, 721.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[251, 45, 2, 8]\n",
      "Smallest group: 1.0, random_state: 7\n",
      "TEST SIZE 1.0 - 45\n",
      "(638, 41) 0.7633228840125392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 1100/1100 [04:28,  4.09it/s, step size=8.13e-04, acc. prob=0.889]\n",
      " 40%|████      | 8/20 [1:24:05<2:04:47, 623.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[251, 44, 2, 9]\n",
      "Smallest group: 1.0, random_state: 8\n",
      "TEST SIZE 1.0 - 44\n",
      "(638, 41) 0.7633228840125392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 1100/1100 [06:35,  2.78it/s, step size=4.82e-04, acc. prob=0.965]\n",
      " 45%|████▌     | 9/20 [1:33:10<1:49:51, 599.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[253, 39, 4, 10]\n",
      "Smallest group: 1.0, random_state: 9\n",
      "TEST SIZE 1.0 - 39\n",
      "(638, 41) 0.7633228840125392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 1100/1100 [05:26,  3.37it/s, step size=7.69e-04, acc. prob=0.926]\n",
      " 50%|█████     | 10/20 [1:41:06<1:33:33, 561.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[240, 54, 3, 9]\n",
      "Smallest group: 1.0, random_state: 10\n",
      "TEST SIZE 1.0 - 54\n",
      "(638, 41) 0.7633228840125392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 1100/1100 [07:33,  2.43it/s, step size=3.90e-04, acc. prob=0.958]\n",
      " 55%|█████▌    | 11/20 [1:51:07<1:26:00, 573.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[245, 48, 2, 11]\n",
      "Smallest group: 3.0, random_state: 11\n",
      "TEST SIZE 3.0 - 11\n",
      "(140, 41) 0.7928571428571428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 1100/1100 [05:11,  3.53it/s, step size=7.86e-04, acc. prob=0.892]\n",
      " 60%|██████    | 12/20 [2:04:31<1:25:48, 643.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[244, 50, 5, 7]\n",
      "Smallest group: 1.0, random_state: 12\n",
      "TEST SIZE 1.0 - 50\n",
      "(638, 41) 0.7633228840125392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 1100/1100 [10:09,  1.80it/s, step size=3.11e-04, acc. prob=0.969]\n",
      " 65%|██████▌   | 13/20 [2:17:09<1:19:08, 678.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[261, 39, 0, 6]\n",
      "Smallest group: 1.0, random_state: 13\n",
      "TEST SIZE 1.0 - 39\n",
      "(638, 41) 0.7633228840125392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 1100/1100 [09:03,  2.02it/s, step size=2.78e-04, acc. prob=0.936]\n",
      " 70%|███████   | 14/20 [2:28:46<1:08:22, 683.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[241, 49, 3, 13]\n",
      "Smallest group: 3.0, random_state: 14\n",
      "TEST SIZE 3.0 - 13\n",
      "(140, 41) 0.7928571428571428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 1100/1100 [06:27,  2.84it/s, step size=6.64e-04, acc. prob=0.931]\n",
      " 75%|███████▌  | 15/20 [2:43:24<1:01:51, 742.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[237, 54, 3, 12]\n",
      "Smallest group: 3.0, random_state: 15\n",
      "TEST SIZE 3.0 - 12\n",
      "(140, 41) 0.7928571428571428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 1100/1100 [06:01,  3.04it/s, step size=5.71e-04, acc. prob=0.957]\n",
      " 80%|████████  | 16/20 [2:57:34<51:38, 774.69s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[250, 49, 0, 7]\n",
      "Smallest group: 1.0, random_state: 16\n",
      "TEST SIZE 1.0 - 49\n",
      "(638, 41) 0.7633228840125392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 1100/1100 [04:40,  3.92it/s, step size=8.52e-04, acc. prob=0.936]\n",
      " 85%|████████▌ | 17/20 [3:04:45<33:34, 671.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[250, 44, 1, 11]\n",
      "Smallest group: 3.0, random_state: 17\n",
      "TEST SIZE 3.0 - 11\n",
      "(140, 41) 0.7928571428571428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 1100/1100 [05:34,  3.29it/s, step size=6.74e-04, acc. prob=0.945]\n",
      " 90%|█████████ | 18/20 [3:18:34<23:57, 718.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[245, 50, 1, 10]\n",
      "Smallest group: 1.0, random_state: 18\n",
      "TEST SIZE 1.0 - 50\n",
      "(638, 41) 0.7633228840125392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 1100/1100 [07:37,  2.41it/s, step size=4.47e-04, acc. prob=0.950]\n",
      " 95%|█████████▌| 19/20 [3:28:41<11:25, 685.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[244, 52, 2, 8]\n",
      "Smallest group: 1.0, random_state: 19\n",
      "TEST SIZE 1.0 - 52\n",
      "(638, 41) 0.7633228840125392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 1100/1100 [06:21,  2.88it/s, step size=6.52e-04, acc. prob=0.960]\n",
      "100%|██████████| 20/20 [3:37:34<00:00, 652.72s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "try:\n",
    "    coverage, width, excess, deficet = uncertainty(\n",
    "        column_metric=column_metric,\n",
    "        ctgans=ctgans[0:10],\n",
    "        X_train=X_train,\n",
    "        X_test=X_test,\n",
    "        X_oracle=X_oracle,\n",
    "        trained_model_dict=trained_model_dict,\n",
    "        random_state=i * 100,\n",
    "        test_group=\"small\",\n",
    "    )\n",
    "    done = True\n",
    "\n",
    "except Exception:\n",
    "    import traceback\n",
    "\n",
    "    print(traceback.format_exc())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9866e5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dname = \"support\"\n",
    "folder = \"../results\"\n",
    "for model in list(coverage.keys()):\n",
    "    mdf_coverage = pd.DataFrame.from_dict(\n",
    "        coverage[model], orient=\"index\", columns=[\"Value\"]\n",
    "    )\n",
    "    mdf_coverage.to_csv(f\"{folder}/coverage_{dname}_{model}.csv\")\n",
    "\n",
    "for model in list(width.keys()):\n",
    "    mdf_width = pd.DataFrame.from_dict(width[model], orient=\"index\", columns=[\"Value\"])\n",
    "    mdf_width.to_csv(f\"{folder}/width_{dname}_{model}.csv\")\n",
    "\n",
    "for model in list(excess.keys()):\n",
    "    mdf_excess = pd.DataFrame.from_dict(\n",
    "        excess[model], orient=\"index\", columns=[\"Value\"]\n",
    "    )\n",
    "    mdf_excess.to_csv(f\"{folder}/excess_{dname}_{model}.csv\")\n",
    "\n",
    "for model in list(deficet.keys()):\n",
    "    mdf_deficit = pd.DataFrame.from_dict(\n",
    "        deficet[model], orient=\"index\", columns=[\"Value\"]\n",
    "    )\n",
    "    mdf_deficit.to_csv(f\"{folder}/deficet_{dname}_{model}.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3s",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
