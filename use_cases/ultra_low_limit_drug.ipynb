{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d7413eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from src.utils import *\n",
    "from src.synthesizer import *\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d49c1e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'drug'\n",
    "column_metric = \"Ethnicity\"\n",
    " \n",
    "seed=0\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd329142",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "\n",
    "def uncertainty(column_metric, ctgans, trained_model_dict, random_state=0, n_samples=5000, test_group='small', smallest_group = 3):\n",
    "        from sklearn.metrics import f1_score\n",
    "\n",
    "        score='acc'\n",
    "\n",
    "        n_samples=1000\n",
    "       \n",
    "        groups = list(np.unique(Data[column_metric]))\n",
    "        orig_random_state = deepcopy(random_state)\n",
    "\n",
    "\n",
    "        for model in ['rf']:#trained_model_dict.keys():\n",
    "\n",
    "\n",
    "            random_state = orig_random_state\n",
    "\n",
    "\n",
    "            try:\n",
    "                trained_model_dict[model].predict_proba(X_train.drop('y', axis=1))\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            means_5 = []\n",
    "            stds_5 = []\n",
    "\n",
    "            means_10 = []\n",
    "            stds_10 = []\n",
    "\n",
    "            oracle_score = []\n",
    "            real_test_score = []\n",
    "\n",
    "\n",
    "            for random_state in range(1):\n",
    "\n",
    "\n",
    "                #smallest_group = 0 \n",
    "                gsizes = []\n",
    "                for idx, group in enumerate(groups):\n",
    "                    gsizes.append(X_val[X_val[column_metric]==group].shape[0])\n",
    "\n",
    "\n",
    "                ns=5\n",
    "                for group in tqdm(groups):\n",
    "\n",
    "                    clf = model_dict[model]\n",
    "\n",
    "\n",
    "                    if group!=smallest_group:\n",
    "                        continue\n",
    "                    \n",
    "                    #n_samples = 1000\n",
    "                    if group==0:\n",
    "                        total_samples = X_val[X_val[column_metric]==0].shape[0]\n",
    "                    else:\n",
    "                        total_samples = n_samples \n",
    "\n",
    "\n",
    "\n",
    "                    test_data = X_val[X_val[column_metric]==group]\n",
    "\n",
    "                    oracle_data = X_test[X_test[column_metric]==group]\n",
    "\n",
    "   \n",
    "\n",
    "                    y_pred = clf.predict(oracle_data.drop('y', axis=1))\n",
    "\n",
    "                    accuracy = accuracy_score(oracle_data['y'], y_pred)\n",
    "\n",
    "                    oracle_score.append(accuracy)\n",
    "\n",
    "                    try:\n",
    "                        y_pred = clf.predict(test_data.drop('y', axis=1))\n",
    "                        accuracy = accuracy_score(test_data['y'], y_pred)\n",
    "                    except:\n",
    "                        accuracy=0.5\n",
    "                    real_test_score.append(accuracy)\n",
    "\n",
    "                    \n",
    "                    if test_data.shape[0]==0:\n",
    "                        accuracy = 0\n",
    "                        TPR=0\n",
    "                        FPR=0\n",
    "                        TNR=0\n",
    "                        FNR=0\n",
    "                        F1=0\n",
    "                        eo_score = 0\n",
    "                        dp_score = 0\n",
    "                    \n",
    "                    else:\n",
    "                        \n",
    "                        #K=5\n",
    "                        syn_accs2 = []\n",
    "                        for ctgan in ctgans[0:5]:\n",
    "                            shift_df, _ = ctgan.sample(1, shift=False, condition_column=column_metric, condition_value=group)\n",
    "\n",
    "                            count=0\n",
    "                            while shift_df.shape[0]<=total_samples:\n",
    "\n",
    "                                generated_tmp, _ = ctgan.sample(n_samples, shift=False, condition_column=column_metric, condition_value=group)\n",
    "\n",
    "                                tmp_df = generated_tmp[generated_tmp[column_metric]==group]\n",
    "\n",
    "                                shift_df = shift_df.append(tmp_df)\n",
    "                                count+=1\n",
    "\n",
    "                            shift_df.shape, count\n",
    "\n",
    "                            syn_data = shift_df[shift_df[column_metric]==group]\n",
    "\n",
    "                            y_pred = clf.predict(syn_data.drop('y', axis=1))\n",
    "\n",
    "                            accuracy = accuracy_score(syn_data['y'], y_pred)\n",
    "\n",
    "                            syn_accs2.append(accuracy)\n",
    "\n",
    "\n",
    "\n",
    "                        mean_syn_acc = np.mean(syn_accs2)\n",
    "                        std_syn_acc = np.std(syn_accs2)\n",
    "\n",
    "\n",
    "                        means_5.append(mean_syn_acc)\n",
    "                        stds_5.append(std_syn_acc)\n",
    "\n",
    "\n",
    "                        # K=10\n",
    "                        syn_accs3 = []\n",
    "                        for ctgan in ctgans:\n",
    "                            shift_df, _ = ctgan.sample(1, shift=False, condition_column=column_metric, condition_value=group)\n",
    "\n",
    "\n",
    "                            count=0\n",
    "                            while shift_df.shape[0]<=total_samples:\n",
    "\n",
    "                                generated_tmp, _ = ctgan.sample(n_samples, shift=False, condition_column=column_metric, condition_value=group)\n",
    "\n",
    "                                tmp_df = generated_tmp[generated_tmp[column_metric]==group]\n",
    "\n",
    "                                shift_df = shift_df.append(tmp_df)\n",
    "                                count+=1\n",
    "\n",
    "                            shift_df.shape, count\n",
    "\n",
    "                            syn_data = shift_df[shift_df[column_metric]==group]\n",
    "\n",
    "                            y_pred = clf.predict(syn_data.drop('y', axis=1))\n",
    "\n",
    "                            accuracy = accuracy_score(syn_data['y'], y_pred)\n",
    "\n",
    "                            syn_accs3.append(accuracy)\n",
    "\n",
    "\n",
    "                        mean_syn_acc = np.mean(syn_accs3)\n",
    "                        std_syn_acc = np.std(syn_accs3)\n",
    "\n",
    "\n",
    "                        means_10.append(mean_syn_acc)\n",
    "                        stds_10.append(std_syn_acc)\n",
    "   \n",
    " \n",
    "        return means_5, means_10, stds_5, stds_10, oracle_score, real_test_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83b3258a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_loader import load_drug_dataset\n",
    "\n",
    "X, y, Data = load_drug_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f0fa564",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training baseline models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 104857.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 53.92it/s]\n",
      " 14%|█▍        | 1/7 [00:53<05:23, 53.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training baseline models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 76858.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 43.73it/s]\n",
      " 29%|██▊       | 2/7 [01:57<04:58, 59.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training baseline models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 113798.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 66.90it/s]\n",
      " 43%|████▎     | 3/7 [02:55<03:55, 58.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training baseline models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 101944.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 69.25it/s]\n",
      " 57%|█████▋    | 4/7 [03:53<02:55, 58.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training baseline models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 93503.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 47.46it/s]\n",
      " 71%|███████▏  | 5/7 [04:52<01:57, 58.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training baseline models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 73954.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 44.46it/s]\n",
      " 86%|████████▌ | 6/7 [06:18<01:07, 67.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training baseline models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 103380.73it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 65.33it/s]\n",
      "100%|██████████| 7/7 [08:32<00:00, 73.23s/it]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "res_loop = []\n",
    "\n",
    "discrete_columns = [\n",
    "      'Age', 'Gender', 'Education', 'Country', column_metric, 'Impulsive', 'SS', 'Alcohol',\n",
    "       'Amphet', 'Amyl', 'Benzos', 'Cannabis', 'Coke', 'Crack', 'Ecstasy',\n",
    "       'Heroin', 'Ketamine', 'Legalh', 'LSD', 'Meth', 'Mushrooms', 'VSA', 'y'\n",
    "    ]\n",
    "\n",
    "groups = list(Data[column_metric].unique())\n",
    "\n",
    "\n",
    "for testsize in tqdm([0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.99]):\n",
    "\n",
    "    res = {}\n",
    "\n",
    "    reslist = {}\n",
    "\n",
    "    for seed in range(1):\n",
    "        \n",
    "        seed=100\n",
    "        seed_everything(seed=seed)\n",
    "    \n",
    "        X_train, X_test = train_test_split(Data, test_size=0.3, random_state=seed)\n",
    "\n",
    "        X_train, X_val = train_test_split(X_train, test_size=0.8, random_state=seed)\n",
    "\n",
    "        _, X_val = train_test_split(X_val, test_size=testsize, random_state=seed)\n",
    "\n",
    "        gsizes = []\n",
    "        for idx, group in enumerate(groups):\n",
    "            gsizes.append(X_val[X_val[column_metric]==group].shape[0])\n",
    "\n",
    "\n",
    "        ctgans = []\n",
    "        trials = []\n",
    "        params_list = []\n",
    "\n",
    "        \n",
    "\n",
    "        from copy import deepcopy\n",
    "        from tqdm import tqdm\n",
    "        for i in range(10):\n",
    "\n",
    "            best_params = {'learning_rate': 0.0002, 'embedding_dim': 256, 'epochs': 100}\n",
    "            ctgan = fit_ctgan(data=X_val, epochs=best_params['epochs'], learning_rate=best_params['learning_rate'], embedding_dim=best_params['embedding_dim'],seed=seed+i, discrete_columns=discrete_columns)\n",
    "\n",
    "            # trials.append(trial_results)\n",
    "            params_list.append(best_params)\n",
    "            ctgans.append(deepcopy(ctgan))\n",
    "\n",
    "\n",
    "        # save each ctgan model in ctgan_list\n",
    "        for idx, ctgan_save in enumerate(ctgans):\n",
    "            ctgan_save.save(f'../models/ctgan_{dataset_name}_{idx+1}')\n",
    "\n",
    "\n",
    "\n",
    "        #pickle best params\n",
    "        with open(f'../models/ctgan_{dataset_name}_params.pkl', 'wb') as f:\n",
    "            pickle.dump(params_list[0], f)\n",
    "\n",
    "\n",
    "\n",
    "        model_dict = {\n",
    "                    'rf': RandomForestClassifier(random_state=0),\n",
    "                }\n",
    "\n",
    "        print('training baseline models')\n",
    "        trained_model_dict = {}\n",
    "\n",
    "        for model in model_dict.keys():\n",
    "            clf = model_dict[model]\n",
    "            clf.fit(X_train.drop('y', axis=1), X_train['y'])\n",
    "\n",
    "            trained_model_dict[model] = deepcopy(clf)\n",
    "\n",
    "\n",
    "        column_metric = column_metric\n",
    "        groups = list(np.unique(Data[column_metric]))\n",
    "\n",
    "\n",
    "        # load ctgans into a list from file 5 pickles\n",
    "        ctgans = []\n",
    "        for i in range(10):\n",
    "            with open(f'../models/ctgan_{dataset_name}_params.pkl', 'rb') as f:\n",
    "                best_params = pickle.load(f)\n",
    "\n",
    "            ctgan = CTGANSynthesizer(embedding_dim=best_params['embedding_dim'], generator_dim=(256, 256), discriminator_dim=(256, 256),\n",
    "                            generator_lr=best_params['learning_rate'], generator_decay=1e-6, discriminator_lr=best_params['learning_rate'],\n",
    "                            discriminator_decay=1e-6, batch_size=500, discriminator_steps=1,\n",
    "                            log_frequency=True, verbose=False, epochs=best_params['epochs'], pac=10, cuda=True)\n",
    "\n",
    "            ctgan = ctgan.load(f'../models/ctgan_{dataset_name}_{i+1}')\n",
    "            \n",
    "            ctgans.append(ctgan)\n",
    "\n",
    "            from tqdm import tqdm\n",
    "            \n",
    "        import warnings\n",
    "        warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "        n_runs=1\n",
    "\n",
    "        for i in tqdm(range(n_runs)):\n",
    "\n",
    "            done=False\n",
    "            tries=0\n",
    "\n",
    "            while done==False:\n",
    "                try:\n",
    "                    means_5, means_10, stds_5, stds_10, oracle_score, test_score = uncertainty(column_metric = column_metric, ctgans=ctgans[0:10], trained_model_dict=trained_model_dict,random_state=i*100, smallest_group=3)\n",
    "                    done=True\n",
    "                    #final_val_dataset.append(val_dataset)\n",
    "                except Exception as e:\n",
    "                    import traceback\n",
    "                    print(traceback.format_exc())\n",
    "                    done=True\n",
    "                    pass\n",
    "            \n",
    "                    \n",
    "                \n",
    "        \n",
    "        try:\n",
    "            res[testsize] =  {\n",
    "                            \"mean5\": means_5,\n",
    "                            \"mean10\": means_10,\n",
    "                            \"std5\": stds_5,\n",
    "                            \"std10\": stds_10,\n",
    "                            \"oracle\": oracle_score,\n",
    "                            \"test\": test_score,\n",
    "                            \"size\": X_val.shape[0],\n",
    "                            \"groupsize\": X_val[X_val[column_metric]==3].shape[0]\n",
    "                        }\n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            print(traceback.format_exc())\n",
    "            print(e)\n",
    "            # pass\n",
    "    \n",
    "\n",
    "\n",
    "        try:\n",
    "            reslist[seed] = res\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        seed+=1\n",
    "\n",
    "\n",
    "    res_loop.append(reslist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0816dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_comparison(dict_list, group=0):\n",
    "    x = []\n",
    "    y_mean10_vs_oracle = []\n",
    "    y_test_vs_oracle = []\n",
    "    yerr = []\n",
    "\n",
    "    for data_dict in dict_list:\n",
    "        for testsize, values in data_dict.items():\n",
    "            # Skip testsize entries with no samples in the target group\n",
    "            if values[\"groupsize\"] == 0:\n",
    "                continue\n",
    "            if len(values[\"mean10\"]) == 0:\n",
    "                continue\n",
    "\n",
    "            # If you want to use a specific group index:\n",
    "            mean10_value  = values[\"mean10\"][group]\n",
    "            test_value    = values[\"test\"][group]\n",
    "            oracle_value  = values[\"oracle\"][group]\n",
    "            std10_value   = values[\"std10\"][group]\n",
    "\n",
    "            mean_abs_error_mean10 = abs(oracle_value - mean10_value)\n",
    "            mean_abs_error_test   = abs(oracle_value - test_value)\n",
    "\n",
    "            x.append(values[\"groupsize\"])\n",
    "            y_mean10_vs_oracle.append(mean_abs_error_mean10)\n",
    "            y_test_vs_oracle.append(mean_abs_error_test)\n",
    "            yerr.append(std10_value)\n",
    "\n",
    "    print(\"Number of points to plot:\", len(x))\n",
    "\n",
    "    plt.errorbar(x, y_mean10_vs_oracle, yerr=yerr, marker=\"o\", linestyle=\"-\", label=\"3S\")\n",
    "    plt.plot(x, y_test_vs_oracle, marker=\"o\", linestyle=\"-\", label=\"Dtest\")\n",
    "    plt.xlabel(\"n Samples in group\")\n",
    "    plt.ylabel(\"Absolute Error vs Oracle\")\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3s",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
